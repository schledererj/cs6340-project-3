{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6340 Project 3 - Deep Learning for Image Classification\n",
    "\n",
    "By Jack Schlederer\n",
    "\n",
    "## Download, Load, and Visualize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by extracting the train-test data from the provided files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_file = np.load('kmnist-train-imgs.npz')\n",
    "train_images = train_images_file['arr_0']\n",
    "train_images_file.close()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_file = np.load('kmnist-train-labels.npz')\n",
    "train_labels = train_labels_file['arr_0']\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_file = np.load('kmnist-test-imgs.npz')\n",
    "test_images = test_images_file['arr_0']\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_file = np.load('kmnist-test-labels.npz')\n",
    "test_labels = test_labels_file['arr_0']\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll spot-check the data by visualizing a few of the samples for the first 4 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0 = filter(lambda x: x[1] == 0, zip(train_images, train_labels))\n",
    "label_1 = filter(lambda x: x[1] == 1, zip(train_images, train_labels))\n",
    "label_2 = filter(lambda x: x[1] == 2, zip(train_images, train_labels))\n",
    "label_3 = filter(lambda x: x[1] == 3, zip(train_images, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "for ax in axes:\n",
    "    image = next(label_0)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image[0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "for ax in axes:\n",
    "    image = next(label_1)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image[0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAADCCAYAAABNCBjaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYmElEQVR4nO3de3DU1fnH8edwTwAbotAICQRQBAoiF8UriNiigkhrnbE4CFbqT/FWRztaC/3BVHH6K2WqcvGCw0VkSkWwgvUCKnKpSrEWCQWEAYwI4X6dJCKwvz+gFdzPkXyTXXb35P2ayQx8OPnmJOzZfVj22cfFYjEDAAAIWY1UbwAAACDZKHgAAEDwKHgAAEDwKHgAAEDwKHgAAEDwKHgAAEDwKHgqwTn3hnNucKLXApmKMwGcjDORflx1eR8e59zBE36bbWZfmdmR47//n1gs9tLp31XiOOcuNrPfmVlXO/Z9LTSz+2Kx2NZU7gvpizMBnIwzEbZq8wxPLBZr8J8PMys2s+tPyP57I3bO1UrdLqukkZk9Z2aFZtbCzA6Y2eRUbgjpjTMBnIwzEbZqU/D4OOeudM5tds497JwrMbPJzrlGzrl5zrkdzrk9x3+df8LnLHTODT3+6yHOuSXOuTHH1250zl1bybUtnXOLnHMHnHMLnHPjnXPTK/J9xGKxN2Kx2MuxWGx/LBYrNbNxZnZZgn5MqEY4E8DJOBNhqPYFz3F5ZpZrxyreO+zYz2Xy8d83N7MyO3bD8OluZmvN7Cwz+z8ze8E55yqxdoaZLTOzM81spJkNOvETnXOfOucGVvB76mFmqyq4Fvg2zgRwMs5EpovFYtXuw8w2mdnVx399pZkdMrN637H+AjPbc8LvF5rZ0OO/HmJm60/4s2wzi5lZXpS1duzAHDaz7BP+fLqZTa/E93e+me02sytS/bPmIzM+OBN88HHyB2civA+e4TlmRywWK//Pb5xz2c65Z51znzvn9pvZIjPLcc7V9Hx+yX9+ETv2NKGZWYOIa5ua2e4TMjOzLyJ+H+acO8fM3jCz+2Ox2OKonw8cx5kATsaZyHAUPMd8u1XtQTM7z8y6x2KxM+zY035mZr6nHxNhq5nlOueyT8gKolzAOdfCzBaY2e9isdiLidwcqh3OBHAyzkSGo+DRGtqx/4/d65zLNbP/TfYXjMVin5vZcjMb6Zyr45y7xMyur+jnO+eamdm7ZjYuFos9k6RtovriTAAn40xkGAoe7U9mlmVmO83sQzN78zR93VvM7BIz22Vmj5nZTDv2PhBmZuacW+Wcu8XzuUPNrJUdOwgH//OR7A2j2viTcSaAE/3JOBMZpdq88WAmcs7NNLM1sVgs6f9yADIBZwI4GWei4niGJ4045y50zrV2ztVwzl1jZjeY2asp3haQMpwJ4GScicrL1HeLDFWemc22Y++vsNnM7orFYp+kdktASnEmgJNxJiqJ/9ICAADB47+0AABA8Ch4AABA8E71Gh7+vyuN7N+/X+YfffSRzK+++mqZ79q1S+Zz5syReV5ensyvv77Cb/+QSMl8U6+KSPszsXnzZpkvWrRI5h07doyUJ9P27dtlvm/fPpnXqqXvwlq2bJmwPWWAoM+Eut+rV6+e3ojnJRp169ZN6J4y0eHDh2U+fvx4mb/22msyz83Nlfnjjz8u8zZt2lRgdwknzwTP8AAAgOBR8AAAgOBR8AAAgOBR8AAAgOCl3RsP+l50dujQIZlXpxejjRo1Sua+F5199tlnMi8o0MN1e/XqJfNWrVpVYHdIF5MmTZL5jBkzZP7OO+8kczuRNGrUSOa+F0r6XrSM9FVcXCxz3/3Ym2/Gj6j6+OOP5VpuD2azZs2SeXl5ucyffPJJmW/cuFHmderUkbnv7I4ePTouO+uss+TaZOMZHgAAEDwKHgAAEDwKHgAAEDwKHgAAEDwKHgAAELxTTUs/7W+jv2LFCpn73rb6qquuknm3bt1k7us4ysrKknnt2rVlXqOGrhV9uXL06FGZ+zrSrrzySpn7Rktce+21Mh86dKjMu3TpIvPCwkKZp0jQb6MfxcqVK2Xu+3ufPXu2zC+66KKE7QkpkVFnYu7cuTLv379/ha+xYMECmffu3TvKVjLa6tWrZe47z0899ZTM9+zZI/MHH3ww0n58IyRUF2h+fn6ka1cCoyUAAED1RMEDAACCR8EDAACCR8EDAACCR8EDAACCl3ZdWj5fffWVzH2vyl+1apXMfR0sX375pcx9HUrbt2+XeWlpaVzWunXrSNfYtWuXzHfu3Cnz9evXy9zHN2+mc+fOMl+yZInMfTNVkiyjOlIS4euvv5Z5v379ZO7r5vv1r3+dqC0hvWTUmTh48KDMzz777Aqv93WU+mZsZbLdu3fLfMyYMTIvKSmRuW/G3rx582R+ww03VGB33/B1gd17772RrpMgdGkBAIDqiYIHAAAEj4IHAAAEj4IHAAAEj4IHAAAET7frpKG6devK/OWXX5b5xIkTZe7rEGjevLnM27VrJ/OpU6fKPDs7Oy7zdVcdPnxY5r7v1deNNWDAAJnn5eXJvKCgQOa5ubkyr1mzpsxxesyZM0fmvnlCv//975O5naTasWOHzNesWSPzrl27ylydQ6SHBg0ayNw3z1DdZ/vuC30dTb77tnTi65i+6aabZH7kyBGZz5w5U+a+OY9FRUUV2N03cnJyZH7zzTdHuk4q8AwPAAAIHgUPAAAIHgUPAAAIHgUPAAAIXsaMlkg3vp+bc/HvaO17cZnvxcB//etfZT5o0CCZ+8ZiNGzYUOYZLqPeRj+q/fv3x2UXXnihXOt7Ye4nn3yS0D1V1dGjR+Oy+fPny7XDhg2T+YYNG2Q+ZMgQmT/zzDMy9zUEZLggzkSPHj1kvnjx4risWbNmcu3atWtlXr9+/cpv7DT5y1/+IvM777xT5m+99ZbMffcXPsuWLZO5b0RNfn6+zH0vfk6nEUQ8wwMAAIJHwQMAAIJHwQMAAIJHwQMAAIJHwQMAAIKXMaMl0o3qxvKJOprBN3LCN/4iEzoQUDGLFi2Kyz777DO51teJlCq+zsWHHnooLpswYYJc27dvX5nv2rVL5r5xBIF2YwXthRdekHmfPn3iMt+4hUy5L9yzZ09cVlJSItdOmzZN5lG7sXy6desmc/VzNzN79dVXZf6zn/1M5tOnT4/LfOc22XiGBwAABI+CBwAABI+CBwAABI+CBwAABI+CBwAABI8urTR08OBBmffq1UvmNWpQt4Zi7ty5cZmv8+SHP/xhsrcTyaxZs2Q+bty4uKxNmzZyrepSMzMrLS2V+dVXX13B3SHd+bpZp0yZEpf55m5liqlTp8Zlvm7Mu+++O6l78T1+PPLIIzL3dWnNnj1b5mPGjInLRowYUbHNJRiPlAAAIHgUPAAAIHgUPAAAIHgUPAAAIHgUPAAAIHjON//muO/8QySHegW/mX+Wlq97K1AVH2KWHAk5E75Oh5tvvjkuGzRokFz7/PPPJ2IrkS1fvlzmAwYMkPno0aPjsuLiYrn28ccfl/m1114r81deeUXmUWbdBSDV32xCzsT5558v8507d8Zl69atk2vTbZaWbwZc27Zt4zLfzCzfbT/ZDh06JPNOnTrJfM2aNTJv1qxZXLZ06VK5tkWLFhXc3SnJM8EzPAAAIHgUPAAAIHgUPAAAIHgUPAAAIHgUPAAAIHjM0kpD7du3l/nixYtlXs26tIKwYMECmavOCN9Mm2Q7evSozIcOHSpzNTPHTHeevfPOO3Jt06ZNZX7//ffLvJp1YwVhx44dMvfNkvrFL34Rl2VlZSV0T8myYsUKmav9d+vWLdnbiaSsrEzmJSUlka5TUFAQlzVu3LhSe6oqnuEBAADBo+ABAADBo+ABAADBo+ABAADBo+ABAADBo0srDb3++usyT7c5MTg1X0fKzJkzZa7mCbVu3Tqhe/o23zw932ysVq1ayVx1Y/l07txZ5qWlpTJ/4IEHZO7rXOSspC9fl4/vdnj77bfHZTVqpNe/1ZctWybz9957T+ajRo2Ky1LVueSjZpiZme3duzfSdVTnaXZ2dmW2VGXpdasBAABIAgoeAAAQPAoeAAAQPAoeAAAQPAoeAAAQPLq0UujIkSMy981f6dmzZzK3gyRYu3atzH2dDrfeemsSd6P5OsZ8HWbz5s2r8tfMzc2V+YQJE2R+4403ynzYsGEynzx5sszTrbunOpoyZYrMVTePWWZ03P3qV7+S+aeffirz1atXJ3M7CbFo0aKEXKdr164JuU4icPoBAEDwKHgAAEDwKHgAAEDwKHgAAEDwKHgAAEDw6NI6DcrLy2Ue9RX8hYWFMvfNH8rKypK5c07mPr5uspo1a0a6Tsi2bdsm84EDB8o8Pz9f5qNHj07Ynr6tuLhY5i+88ILMb7vtNpmfeeaZCdvTt/Xv31/mPXr0kPm0adNkrmaSmZn98pe/lDm35dOnqKhI5r75as2bN0/mdiJZv369zDdt2iTz1157TeZ5eXmJ2lKV+brjnn322UjX6dOnj8wfe+yxyHtKFp7hAQAAwaPgAQAAwaPgAQAAwaPgAQAAwaPgAQAAwaNLK8FisVhcNmbMGLl27NixMt+zZ4/MfbO0fF1UiXL06FGZ09nyjTfeeEPmX3zxhcy7d+8u87p161Z5L2vWrJH5kCFDZL5hwwaZz5gxo8p7icp3m/J1r1122WUyHzFihMz79u0r87Zt21Zgd0iE7du3y7xfv34yT8SZiMo36+6OO+6QuW823BVXXJGoLSXNv/71L5n7unx//OMfy3zSpEky9/1sUoFneAAAQPAoeAAAQPAoeAAAQPAoeAAAQPB40XKCqXER48ePl2vLysoiXbugoEDmDRs2jHSdqGrXrp3U62eSffv2yXzUqFGRrtOpU6ek7WXw4MEyX758eaT1jRs3rtzGkqBr164yb9mypcw3btwo84kTJ8r8ySefrNzG4OVrvli3bp3MfS/kTwXf7eS9996T+dtvv53M7STV008/LfOlS5fKvH379jLPyclJ1JaShmd4AABA8Ch4AABA8Ch4AABA8Ch4AABA8Ch4AABA8OjSqqT9+/fLXL01focOHeTawsJCmfveovvw4cMy941+qFGDejbRfKMiNm3aFOk6l19+eZX34nuL99WrV8u8WbNmMh8+fHiV95JsvvECTZs2lbmvS2vevHky/81vfiPzJk2aVGB3UIqKimTuu1/ydf8kk+8+1Tcq5pJLLpF5r169Eran061BgwYy//rrr2XeqlUrmWfC40367xAAAKCKKHgAAEDwKHgAAEDwKHgAAEDwKHgAAEDw6NKqpDp16shcdRqceeaZcu1HH30U6Wu+//77Mi8vL5d5VlaWzJ1zkb4uvrF+/fqEXMd3m4jFYnHZ7bffLtf6bg+qU9DM7LbbbpO5r+siE5xzzjky980B2rp1q8x9XZd0aVXeuHHjZD5kyBCZp+J2uGDBApmvWLFC5nPnzpV5rVqZ+1Dqu1+YOnWqzA8dOiTzDz74QOZdunSJy3xdl8nGMzwAACB4FDwAACB4FDwAACB4FDwAACB4FDwAACB4mfvS8hSrV69ehdf+5Cc/kfnMmTMjfc3mzZvLfOXKlTLv3r17pOvj1DZs2JCQ61xxxRUynzJlSlw2efLkhHzNc889NyHXSSdbtmyJtL6srEzm27dvl7mvCwzfOHDggMzfeustmfu6t5LJ15131113yfziiy+WeY8ePRK2p3TRrl07mftu+6+//rrM//a3v8m8d+/ecVlBQYFc+/DDD8s8Pz9f5vXr15e5D8/wAACA4FHwAACA4FHwAACA4FHwAACA4FHwAACA4NGldRpcd911Mu/QoYPMi4qKZF5YWCjzI0eOyLy0tFTm2dnZMsepLV68ONL6vLw8mc+ZM0fmvrlZUdxzzz0yHzhwYJWvnW58Z2j+/Pky9808+v73v5+wPVU3n3zyicz37dsnczVvMNlmzJghc9995PDhw5O5nbTSsGFDmd9yyy0yf+SRR2Su5gCa+eeVKb77xY4dO8r8Rz/6kcx9f388wwMAAIJHwQMAAIJHwQMAAIJHwQMAAIJHwQMAAIJHl9Zp0KBBA5k/9thjMh8wYIDMb7rpJpk3atRI5m+++abMr7nmGpnTvXVqa9asibR+7969Mh85cqTMfZ0Oim8ejW92W40a4f37JmrXVefOnWXeunXrhO2pulmyZEmk9am4HZaUlMh84cKFMvfNlwrR3//+d5l/+OGHp3kn/vtLX3fsxo0bZU6XFgAAqLYoeAAAQPAoeAAAQPAoeAAAQPAoeAAAQPDo0jru6NGjMk9mR0GTJk1knpOTI3NfJ0lWVpbML7roIpnPnj1b5jfccIPMfbNWqqOoXVrl5eUy93UXRHHppZfKvGfPnlW+dqZYuXKlzLdt2yZz38996tSpMh88eHDlNlaNFBcXR1rvmy+XCNOnT5d53759ZZ5O3Vi7d++Wua97tk6dOjKP+ljm61x86qmnZD5ixAiZ79ixQ+bqPnPr1q1y7ccffyzzpUuXytz39+rDMzwAACB4FDwAACB4FDwAACB4FDwAACB4FDwAACB47hSzeyo+2CfDHTp0SOa+V8InwtixY2U+b948mb/77ruRru97tf6WLVtkfsYZZ8jc16XlnIu0nwRJyRf97xd3LqlnIjc3Ny7z/T1+8MEHMm/btm1C95TOioqKZN6pUyeZt2nTRubr16+X+eWXXy7z3/72tzLv1auXzJMspWfi0ksvlWfCd/v0dTqed955Ff6aa9eulfkFF1wg82nTpsncN58wUXyPr+rxZuDAgXLtHXfcIfM+ffpUfmNpyndf9+WXX8rc1/FXu3ZteSZ4hgcAAASPggcAAASPggcAAASPggcAAASPggcAAASv2s3S8s3w+Pe//y3z3r17J20vy5cvl/nFF1+ckOv7Zqfk5+fL3NeptnfvXpk3atSoUvuCn5qn8/Of/1yurU7dWD4dOnSQ+fjx42X+wAMPyPzw4cMy37lzp8yvuuoqmXfs2DEu++lPfyrX3nrrrTIvKCiQec2aNWWeavv374+0fvXq1TKP0qX16quvytzXpeWbE5hsEydOlHlZWVlc5uskq1+/fkL3lM58j1m+MxH5+gm5CgAAQBqj4AEAAMGj4AEAAMGj4AEAAMGj4AEAAMGrdrO0Nm3aJHNfl9Z1111X5a/pmw9SWFgo87vvvlvmDz/8cJX3EoCUzg3KycmRZ2Lfvn0Jub7qoNu4caNcW6tWtWuyrLK3335b5g899JDMN2/eLPM9e/YkbE/f1qJFC5kvW7ZM5k2aNEnpmXjiiSfkmXj00Ufl+rvuukvmEyZMkPkrr7wSl/k61s4//3yZt2rVSubJtmPHDpnXq1cvLvPNLESlMEsLAABUTxQ8AAAgeBQ8AAAgeBQ8AAAgeNXuRculpaUyHz58uMz/8Ic/yDzK27yXlJTIvGnTpjKfPXu2zPv37y9z39txByqlL9DMy8uTZ2Lbtm2RruMbC7Fo0aK4rHHjxpGunSjvv/++zBcvXizze+65R+Y5OTmJ2lLSHDhwQOb//Oc/Zf7ss8/KfNWqVXHZypUr5dq6devKvLy8XOZDhgyR+eTJk1N6JjZt2iTPRJs2beR632ibSZMmyVx9374XOPfr10/mSC++x8R169bJ3DdC5jvGG/GiZQAAUD1R8AAAgOBR8AAAgOBR8AAAgOBR8AAAgOBVu/emz8rKkvkPfvADmX/11Vcyz87OrvDXLC4ulrmvQ65Lly4ydy6lzRgws169esn8z3/+c6TrPPHEEzJPVUeW4vuennnmGZlPmzZN5mpUyqBBg+Ta3NzcCu4usXxv69+zZ89IuRoj8+KLL8q1vpEhf/zjH2Xu6xhLNd+InM6dO8vcNyKjT58+MlcdOt26davY5pBwS5YskbnvsbVjx45x2ciRI+VaX/djy5YtZT5u3DiZ+0ZC8QwPAAAIHgUPAAAIHgUPAAAIHgUPAAAIHgUPAAAIXrXr0vJ1Op177rky//zzz2Xerl27Ku+lSZMmMj/77LNlTpdW6o0dO1bmaoaSmVn9+vVl3r59e5kPGzYsLvN1hvlug82aNZO5b0ZTrVr6bsA3p8Y3u23r1q0yf+mll+IyX5dWplM/m8GDB0e6xn333SfzzZs3V2pPqeLruPH93RcVFcn8xhtvjMvy8vIqvzFUia/L7tFHH5X5BRdcEJfdf//9cu2GDRtkPn/+fJmr24aZWVlZmcx5hgcAAASPggcAAASPggcAAASPggcAAASPggcAAATP+eY5HfedfxgSNQPHzGzhwoUy93XOqE6q559/Xq597rnnZP6Pf/xD5j779u2T+fe+971I18kQqW5Vk2fC16FUt25dmftmRu3duzcui9qd47v2gQMHZF6nTh2Z+24/W7ZsibQf1QHp+7mgUtLyTPi8++67Mp81a5bM77333rgsEV2yqBxft+fTTz8tc/V45pu/duedd8rc9/js20uHDh3kmeAZHgAAEDwKHgAAEDwKHgAAEDwKHgAAEDwKHgAAELxTdWkBAABkPJ7hAQAAwaPgAQAAwaPgAQAAwaPgAQAAwaPgAQAAwaPgAQAAwft/A7UQlqgf5k0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "for ax in axes:\n",
    "    image = next(label_2)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image[0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "for ax in axes:\n",
    "    image = next(label_3)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image[0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Training: %i' % image[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the features\n",
    "\n",
    "We'll flatten the 2D 28 x 28 pixel arrays to 1D 784 pixel arrays. We could use scikit-learn's `StandardScaler` here to scale the values to have a 0 mean and 1 std. deviation, but Keras has a built-in scaler, so we'll include that as part of the deep learning model in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_flat = train_images.reshape(60000, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a multi-layer perceptron\n",
    "\n",
    "Using Keras, we'll build up a simple multi-layer perceptron model with an input layer, a scaling layer, 2 hidden dense layers, and an output dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 6280      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,442\n",
      "Trainable params: 6,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use a sequential, linear stack of layers\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add an input layer\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(28*28,)))\n",
    "\n",
    "# Add a scaler to scale the [0, 255] values to [0, 1]\n",
    "model.add(tf.keras.layers.Rescaling(scale=1./255))\n",
    "\n",
    "# Add 2 dense layers with 8 nodes each, with RELU activation functions\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "\n",
    "# Add a dense layer with N nodes (N being the number of classes) and a softmax activation function\n",
    "num_classes = len(set(train_labels))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compile the model. The `compile` function takes input arguments for the loss function, the optimizer, and additional metrics to calculate along with loss. Since we're classifying with >2 labels and the labels are provided in integer format, we'll use the `SparseCategoricalCrossentropy` loss function. There are several options for the optimizer class, with no immediately apparent advantages or disadvantages over the others, so we'll use the one that was used in the MNIST tutorial, `RMSprop`. As for additional metrics, we'll take `accuracy`, which is more immediately indicative of the model's performance than loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.RMSprop(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 6280      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,442\n",
      "Trainable params: 6,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a freshly-compiled model, we're ready to train! Fitting a deep learning model has more tunable parameters than a run-of-the-mill ML model, but we'll just be tuning the batch size and number of epochs to train over. For the first run, we'll just use a batch size of the default of 32, and 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 941us/step - loss: 1.0693 - accuracy: 0.6638\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 814us/step - loss: 0.6866 - accuracy: 0.7915\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 863us/step - loss: 0.6267 - accuracy: 0.8098\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 828us/step - loss: 0.5968 - accuracy: 0.8177\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 847us/step - loss: 0.5765 - accuracy: 0.8248\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 826us/step - loss: 0.5632 - accuracy: 0.8298\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 818us/step - loss: 0.5528 - accuracy: 0.8320\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 866us/step - loss: 0.5455 - accuracy: 0.8338\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 827us/step - loss: 0.5387 - accuracy: 0.8362\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 820us/step - loss: 0.5335 - accuracy: 0.8388\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_images_flat,\n",
    "    y=train_labels,\n",
    "    batch_size=32,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.88%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {(history.history['accuracy'][-1] * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is decent accuracy for a first pass, but keep in mind it's only the accuracy of the final pass of _training_. We don't know how it will fare against the testing dataset. Let's play around with some of the parameters. First off, let's \"functionize\" the creation and training of the model, the predictions, and the accuracy calculation. I want to be able to pass the optimizer, the number of training epochs, the number of hidden dense layers, and the number of nodes in the hidden dense layers as inputs, and get an accuracy score against the testing images as an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_flat = test_images.reshape(10000, 28*28)\n",
    "\n",
    "def compile_fit_model_and_predict(num_epochs, num_hidden_dense_layers, num_dense_layer_nodes, optimizer):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(28*28,)))\n",
    "    model.add(tf.keras.layers.Rescaling(scale=1./255))\n",
    "\n",
    "    for i in range(0, num_hidden_dense_layers):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            num_dense_layer_nodes, activation='relu'))\n",
    "\n",
    "    # Add a dense layer with N nodes (N being the number of classes) and a softmax activation function\n",
    "    num_classes = len(set(train_labels))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x=train_images_flat,\n",
    "        y=train_labels,\n",
    "        batch_size=32,\n",
    "        epochs=num_epochs,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(test_images_flat)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    return {\n",
    "        'Number of epochs': num_epochs,\n",
    "        'Number of hidden layers': num_hidden_dense_layers,\n",
    "        'Number of nodes per hidden layer': num_dense_layer_nodes,\n",
    "        'Optimizer class': type(optimizer),\n",
    "        'Accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, we'll try changing up the optimizer. It's difficult to tell which optimizer will perform the best just from the documentation, so we'll run a few experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers as op\n",
    "\n",
    "optimizers = [\n",
    "    op.SGD(),\n",
    "    op.Adam(),\n",
    "    op.Adadelta(),\n",
    "    op.Adagrad(),\n",
    "    op.Adamax(),\n",
    "    op.Nadam(),\n",
    "    op.Ftrl()\n",
    "]\n",
    "\n",
    "results = list()\n",
    "for _opt in optimizers:\n",
    "    results.append(compile_fit_model_and_predict(10, 2, 8, _opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of epochs</th>\n",
       "      <th>Number of hidden layers</th>\n",
       "      <th>Number of nodes per hidden layer</th>\n",
       "      <th>Optimizer class</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.nadam.Nadam'&gt;</td>\n",
       "      <td>0.7034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.7010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adamax.Adamax'&gt;</td>\n",
       "      <td>0.6919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.gradient_descent.SGD'&gt;</td>\n",
       "      <td>0.6743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adagrad.Adagrad'&gt;</td>\n",
       "      <td>0.4684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adadelta.Adadelta'&gt;</td>\n",
       "      <td>0.1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.ftrl.Ftrl'&gt;</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of epochs  Number of hidden layers  \\\n",
       "5                10                        2   \n",
       "1                10                        2   \n",
       "4                10                        2   \n",
       "0                10                        2   \n",
       "3                10                        2   \n",
       "2                10                        2   \n",
       "6                10                        2   \n",
       "\n",
       "   Number of nodes per hidden layer  \\\n",
       "5                                 8   \n",
       "1                                 8   \n",
       "4                                 8   \n",
       "0                                 8   \n",
       "3                                 8   \n",
       "2                                 8   \n",
       "6                                 8   \n",
       "\n",
       "                                     Optimizer class  Accuracy  \n",
       "5           <class 'keras.optimizer_v2.nadam.Nadam'>    0.7034  \n",
       "1             <class 'keras.optimizer_v2.adam.Adam'>    0.7010  \n",
       "4         <class 'keras.optimizer_v2.adamax.Adamax'>    0.6919  \n",
       "0  <class 'keras.optimizer_v2.gradient_descent.SGD'>    0.6743  \n",
       "3       <class 'keras.optimizer_v2.adagrad.Adagrad'>    0.4684  \n",
       "2     <class 'keras.optimizer_v2.adadelta.Adadelta'>    0.1326  \n",
       "6             <class 'keras.optimizer_v2.ftrl.Ftrl'>    0.1000  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the `Adam` and `Nadam` optimizers outperform the others just slightly, at least with the current, fixed set of parameters, so let's stick with `Adam`. Now, let's generate some permutations of the other parameters to build and fit the model with, and then calculate the accuracy of their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "epochs_options = [25, 50]\n",
    "hidden_layers_options = [0, 1, 2]\n",
    "hidden_layer_nodes_options = [32, 64, 128]\n",
    "optimizer_options = [op.Adam()]\n",
    "\n",
    "results = list()\n",
    "for args in product(epochs_options, hidden_layers_options, hidden_layer_nodes_options, optimizer_options):\n",
    "    results.append(compile_fit_model_and_predict(*args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each model, I recorded the accuracy of the predictions. The following table shows the accuracies for each model, with the most accurate on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of epochs</th>\n",
       "      <th>Number of hidden layers</th>\n",
       "      <th>Number of nodes per hidden layer</th>\n",
       "      <th>Optimizer class</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.6979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.6971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.6953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.6951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.6919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of epochs  Number of hidden layers  \\\n",
       "8                 25                        2   \n",
       "17                50                        2   \n",
       "5                 25                        1   \n",
       "14                50                        1   \n",
       "7                 25                        2   \n",
       "16                50                        2   \n",
       "4                 25                        1   \n",
       "13                50                        1   \n",
       "6                 25                        2   \n",
       "15                50                        2   \n",
       "3                 25                        1   \n",
       "12                50                        1   \n",
       "10                50                        0   \n",
       "11                50                        0   \n",
       "0                 25                        0   \n",
       "9                 50                        0   \n",
       "1                 25                        0   \n",
       "2                 25                        0   \n",
       "\n",
       "    Number of nodes per hidden layer                         Optimizer class  \\\n",
       "8                                128  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "17                               128  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "5                                128  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "14                               128  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "7                                 64  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "16                                64  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "4                                 64  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "13                                64  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "6                                 32  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "15                                32  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "3                                 32  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "12                                32  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "10                                64  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "11                               128  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "0                                 32  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "9                                 32  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "1                                 64  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "2                                128  <class 'keras.optimizer_v2.adam.Adam'>   \n",
       "\n",
       "    Accuracy  \n",
       "8     0.9017  \n",
       "17    0.8974  \n",
       "5     0.8921  \n",
       "14    0.8847  \n",
       "7     0.8808  \n",
       "16    0.8784  \n",
       "4     0.8683  \n",
       "13    0.8629  \n",
       "6     0.8363  \n",
       "15    0.8295  \n",
       "3     0.8237  \n",
       "12    0.8040  \n",
       "10    0.6979  \n",
       "11    0.6971  \n",
       "0     0.6970  \n",
       "9     0.6953  \n",
       "1     0.6951  \n",
       "2     0.6919  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the most accurate model is built with 2 hidden layers of 128 nodes (or _neurons_) each, and is trained on 25 epochs. Now, let's try the same experiments with a _convolutional_ neural network (CNN).\n",
    "\n",
    "## Implementing a Convolutional Neural Network\n",
    "\n",
    "Next up, we'll build a convolutional network using largely the same patterns as the multi-layer network. This time, instead of using the flattened, 1D images as inputs, we'll input the 2D arrays and then flatten after some 2D convolution and pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_378 (Dense)           (None, 128)               1179776   \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_380 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,216,394\n",
      "Trainable params: 1,216,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# use 2 dense layers with 128 nodes, per the most accurate perceptron model from the previous section\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "num_classes = len(set(train_labels))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=op.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 72s 151ms/step - loss: 0.9309 - accuracy: 0.8899\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0818 - accuracy: 0.9759\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.0442 - accuracy: 0.9862\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0321 - accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 0.0222 - accuracy: 0.9929\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 0.0237 - accuracy: 0.9922\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0235 - accuracy: 0.9927\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 70s 150ms/step - loss: 0.0151 - accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 71s 150ms/step - loss: 0.0172 - accuracy: 0.9944\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 0.0135 - accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218babf65b0>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_images, y=train_labels, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9289\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. We're already about 2% better than the perceptron with only the first pass! Since this took a long time to run (11 mins, compared to the perceptrons, which took ~15 sec), I'd like to increase the batch size to see how it impacts time to fit and the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 66s 278ms/step - loss: 1.1770 - accuracy: 0.8524\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 65s 275ms/step - loss: 0.0848 - accuracy: 0.9760\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 64s 274ms/step - loss: 0.0423 - accuracy: 0.9877\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 65s 275ms/step - loss: 0.0215 - accuracy: 0.9937\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 65s 277ms/step - loss: 0.0166 - accuracy: 0.9947\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 65s 276ms/step - loss: 0.0131 - accuracy: 0.9956\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 66s 281ms/step - loss: 0.0127 - accuracy: 0.9958\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 66s 281ms/step - loss: 0.0149 - accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 65s 277ms/step - loss: 0.0126 - accuracy: 0.9960\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 65s 275ms/step - loss: 0.0099 - accuracy: 0.9969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2186f98be50>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# use 2 dense layers with 128 nodes, per the most accurate perceptron model from the previous section\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "num_classes = len(set(train_labels))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=op.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x=train_images, y=train_labels, batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9335\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, neither the timing nor the accuracy improved, but they also didn't worsen. We'll stick with this one, though. Let's functionize all this such that we can easily pass in different parameters in an attempt to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "def compile_fit_cnn_model_and_predict(num_epochs, num_filters, kernel_size, pooling, optimizer):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_filters*2, kernel_size=kernel_size, activation='relu'))\n",
    "\n",
    "    if pooling == 'max':\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "    if pooling == 'global':\n",
    "        model.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # use 2 dense layers with 128 nodes, per the most accurate perceptron model from the previous section\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "    num_classes = len(set(train_labels))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=op.Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x=train_images,\n",
    "        y=train_labels,\n",
    "        batch_size=256,\n",
    "        epochs=num_epochs,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(test_images)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    return {\n",
    "        'Number of epochs': num_epochs,\n",
    "        'Number of filters': num_filters,\n",
    "        'Kernel size': kernel_size,\n",
    "        'Pooling type': pooling or 'none',\n",
    "        'Optimizer class': type(optimizer),\n",
    "        'Accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interest of time, we'll stick with the `Adam` optimizer to cut down on the number of permutations of the parameters. It's important to keep in mind, however, that varying the optimizer class is yet another dial one could turn to get better timing and/or accuracy of the model. Similarly, we're only going to test a set of 3 options for each of the other parameters so it doesn't take too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_options = [5, 10, 15]\n",
    "num_filters_options = [16, 32, 64]\n",
    "kernel_size_options = [3, 5, 7]\n",
    "pooling_options = ['max', 'global', 'none']\n",
    "optimizer_options = [op.Adam()]\n",
    "\n",
    "results = list()\n",
    "for args in product(epochs_options, num_filters_options, kernel_size_options, pooling_options, optimizer_options):\n",
    "    results.append(compile_fit_cnn_model_and_predict(*args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I had to kill this cell after running for 1,285 minutes, _but_ it had finished predictions on models using 76 of the possible 81 permutations of hyperparameters by that point. Let's take a look at those results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of epochs</th>\n",
       "      <th>Number of filters</th>\n",
       "      <th>Kernel size</th>\n",
       "      <th>Pooling type</th>\n",
       "      <th>Optimizer class</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>max</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.9316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of epochs  Number of filters  Kernel size Pooling type  \\\n",
       "36                10                 32            3          max   \n",
       "48                10                 64            5          max   \n",
       "66                15                 32            5          max   \n",
       "39                10                 32            5          max   \n",
       "24                 5                 64            7          max   \n",
       "75                15                 64            5          max   \n",
       "69                15                 32            7          max   \n",
       "51                10                 64            7          max   \n",
       "27                10                 16            3          max   \n",
       "21                 5                 64            5          max   \n",
       "\n",
       "                           Optimizer class  Accuracy  \n",
       "36  <class 'keras.optimizer_v2.adam.Adam'>    0.9374  \n",
       "48  <class 'keras.optimizer_v2.adam.Adam'>    0.9345  \n",
       "66  <class 'keras.optimizer_v2.adam.Adam'>    0.9340  \n",
       "39  <class 'keras.optimizer_v2.adam.Adam'>    0.9336  \n",
       "24  <class 'keras.optimizer_v2.adam.Adam'>    0.9335  \n",
       "75  <class 'keras.optimizer_v2.adam.Adam'>    0.9329  \n",
       "69  <class 'keras.optimizer_v2.adam.Adam'>    0.9329  \n",
       "51  <class 'keras.optimizer_v2.adam.Adam'>    0.9322  \n",
       "27  <class 'keras.optimizer_v2.adam.Adam'>    0.9318  \n",
       "21  <class 'keras.optimizer_v2.adam.Adam'>    0.9316  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)\n",
    "results_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of epochs</th>\n",
       "      <th>Number of filters</th>\n",
       "      <th>Kernel size</th>\n",
       "      <th>Pooling type</th>\n",
       "      <th>Optimizer class</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.8016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.7424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.7326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.7038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.6894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>global</td>\n",
       "      <td>&lt;class 'keras.optimizer_v2.adam.Adam'&gt;</td>\n",
       "      <td>0.6113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of epochs  Number of filters  Kernel size Pooling type  \\\n",
       "31                10                 16            5       global   \n",
       "46                10                 64            3       global   \n",
       "64                15                 32            3       global   \n",
       "37                10                 32            3       global   \n",
       "4                  5                 16            5       global   \n",
       "19                 5                 64            3       global   \n",
       "55                15                 16            3       global   \n",
       "10                 5                 32            3       global   \n",
       "28                10                 16            3       global   \n",
       "1                  5                 16            3       global   \n",
       "\n",
       "                           Optimizer class  Accuracy  \n",
       "31  <class 'keras.optimizer_v2.adam.Adam'>    0.8230  \n",
       "46  <class 'keras.optimizer_v2.adam.Adam'>    0.8037  \n",
       "64  <class 'keras.optimizer_v2.adam.Adam'>    0.8016  \n",
       "37  <class 'keras.optimizer_v2.adam.Adam'>    0.7613  \n",
       "4   <class 'keras.optimizer_v2.adam.Adam'>    0.7591  \n",
       "19  <class 'keras.optimizer_v2.adam.Adam'>    0.7424  \n",
       "55  <class 'keras.optimizer_v2.adam.Adam'>    0.7326  \n",
       "10  <class 'keras.optimizer_v2.adam.Adam'>    0.7038  \n",
       "28  <class 'keras.optimizer_v2.adam.Adam'>    0.6894  \n",
       "1   <class 'keras.optimizer_v2.adam.Adam'>    0.6113  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of CNN models tested with over 90% accuracy: 60.53%\n"
     ]
    }
   ],
   "source": [
    "num_models_over_90_pct_accurate = results_df[results_df['Accuracy'] > 0.9].shape[0]\n",
    "print(f\"Percentage of CNN models tested with over 90% accuracy: {(num_models_over_90_pct_accurate / results_df.shape[0] * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top performing CNN model improved by about 3% over the multi-layer perceptron, and possibly even more if the other 5 permutations were allowed to complete. It's also worth noting that over half of the CNN models tested showed an accuracy of over 90%, where as only 1 of the 18 perceptron models (5.6%) performed that well. The CNN models, however, take an _extreme_ amount of time to run, so only if one has the time to spare, or a particularly beefy computer or cluster thereof, should CNNs be considered.\n",
    "\n",
    "## Appendix\n",
    "\n",
    "This section is just for generating outputs to be used in the accompanying report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_124 (Rescaling)   (None, 784)               0         \n",
      "                                                                 \n",
      " dense_627 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_628 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_629 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def compile_perceptron_model(num_epochs, num_hidden_dense_layers, num_dense_layer_nodes, optimizer):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(28*28,)))\n",
    "    model.add(tf.keras.layers.Rescaling(scale=1./255))\n",
    "\n",
    "    for i in range(0, num_hidden_dense_layers):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            num_dense_layer_nodes, activation='relu'))\n",
    "\n",
    "    # Add a dense layer with N nodes (N being the number of classes) and a softmax activation function\n",
    "    num_classes = len(set(train_labels))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "compile_perceptron_model(25, 2, 128, op.Adam()).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_183 (Conv2D)         (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_184 (Conv2D)         (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 12, 12, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_90 (Flatten)        (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_633 (Dense)           (None, 128)               1179776   \n",
      "                                                                 \n",
      " dense_634 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_635 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,216,394\n",
      "Trainable params: 1,216,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "def compile_cnn_model(num_epochs, num_filters, kernel_size, pooling, optimizer):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_filters*2, kernel_size=kernel_size, activation='relu'))\n",
    "\n",
    "    if pooling == 'max':\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "    elif pooling == 'global':\n",
    "        model.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # use 2 dense layers with 128 nodes, per the most accurate perceptron model from the previous section\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "    num_classes = len(set(train_labels))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=op.Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "compile_cnn_model(10, 32, 3, 'max', op.Adam()).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3707 - accuracy: 0.8871\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1727 - accuracy: 0.9484\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1191 - accuracy: 0.9641\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0883 - accuracy: 0.9723\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0676 - accuracy: 0.9783\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0538 - accuracy: 0.9827\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0442 - accuracy: 0.9856\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0353 - accuracy: 0.9882\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0328 - accuracy: 0.9890\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0278 - accuracy: 0.9913\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0275 - accuracy: 0.9908\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0229 - accuracy: 0.9922\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0199 - accuracy: 0.9933\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0202 - accuracy: 0.9935\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0229 - accuracy: 0.9924\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0173 - accuracy: 0.9942\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0183 - accuracy: 0.9942\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0161 - accuracy: 0.9948\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0174 - accuracy: 0.9945\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0186 - accuracy: 0.9944\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0151 - accuracy: 0.9949\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0142 - accuracy: 0.9959\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0159 - accuracy: 0.9949\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0134 - accuracy: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[929,   1,   1,   2,  23,  12,   5,  14,   9,   4],\n",
       "       [  2, 882,  22,   3,  15,  14,  29,   4,  14,  15],\n",
       "       [  8,   6, 847,  40,   6,  41,  13,  11,  15,  13],\n",
       "       [  3,   4,  16, 952,   2,  10,   4,   2,   5,   2],\n",
       "       [ 14,  18,   4,  10, 899,   7,   9,  10,  24,   5],\n",
       "       [  4,  12,  15,   9,   6, 941,   5,   1,   4,   3],\n",
       "       [  7,   9,  14,   6,  28,   9, 919,   4,   2,   2],\n",
       "       [ 16,  10,  14,   8,  22,  10,  19, 868,  13,  20],\n",
       "       [ 10,  12,   8,  18,   7,  10,  10,   1, 921,   3],\n",
       "       [ 13,   8,  32,   7,  32,   8,   9,   6,  19, 866]], dtype=int64)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_images_flat = test_images.reshape(10000, 28*28)\n",
    "\n",
    "def compile_fit_model_and_predict_with_confusion_matrix(num_epochs, num_hidden_dense_layers, num_dense_layer_nodes, optimizer):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(28*28,)))\n",
    "    model.add(tf.keras.layers.Rescaling(scale=1./255))\n",
    "\n",
    "    for i in range(0, num_hidden_dense_layers):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            num_dense_layer_nodes, activation='relu'))\n",
    "\n",
    "    # Add a dense layer with N nodes (N being the number of classes) and a softmax activation function\n",
    "    num_classes = len(set(train_labels))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x=train_images_flat,\n",
    "        y=train_labels,\n",
    "        batch_size=32,\n",
    "        epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(test_images_flat)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return confusion_matrix(test_labels, predictions)\n",
    "\n",
    "compile_fit_model_and_predict_with_confusion_matrix(25, 2, 128, op.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 66s 276ms/step - loss: 1.6551 - accuracy: 0.7995\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 65s 276ms/step - loss: 0.1150 - accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 68s 291ms/step - loss: 0.0612 - accuracy: 0.9818\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 66s 283ms/step - loss: 0.0332 - accuracy: 0.9898\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 64s 274ms/step - loss: 0.0209 - accuracy: 0.9934\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 64s 273ms/step - loss: 0.0164 - accuracy: 0.9945\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 64s 273ms/step - loss: 0.0141 - accuracy: 0.9953\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 64s 273ms/step - loss: 0.0171 - accuracy: 0.9937\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 69s 294ms/step - loss: 0.0164 - accuracy: 0.9942\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 67s 284ms/step - loss: 0.0113 - accuracy: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[959,   2,   0,   0,   8,   3,   0,  17,   8,   3],\n",
       "       [  2, 939,   4,   0,   6,   4,  31,   3,   4,   7],\n",
       "       [  8,   7, 842,  38,   9,  24,  28,  22,  15,   7],\n",
       "       [  3,   2,   5, 966,   0,  11,   4,   3,   4,   2],\n",
       "       [ 23,   3,   5,  14, 887,  14,  14,  11,  28,   1],\n",
       "       [  2,   6,  25,  10,   3, 934,  12,   3,   2,   3],\n",
       "       [  3,  16,   8,   4,   3,   2, 954,   8,   2,   0],\n",
       "       [ 10,   9,   1,   2,   4,   3,  10, 944,   6,  11],\n",
       "       [  8,  15,   4,   4,   2,   0,   7,   3, 956,   1],\n",
       "       [ 16,  11,   8,   3,  12,   4,   5,  14,  10, 917]], dtype=int64)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compile_fit_cnn_model_and_predict_with_confusion_matrix(num_epochs, num_filters, kernel_size, pooling, optimizer):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(28, 28, 1)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_filters, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_filters*2, kernel_size=kernel_size, activation='relu'))\n",
    "\n",
    "    if pooling == 'max':\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "    if pooling == 'global':\n",
    "        model.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # use 2 dense layers with 128 nodes, per the most accurate perceptron model from the previous section\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "    num_classes = len(set(train_labels))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=op.Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x=train_images,\n",
    "        y=train_labels,\n",
    "        batch_size=256,\n",
    "        epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(test_images)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return confusion_matrix(test_labels, predictions)\n",
    "\n",
    "compile_fit_cnn_model_and_predict_with_confusion_matrix(10, 32, 3, 'max', op.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_2 = filter(lambda x: x[1] == 2, zip(test_images, test_labels))\n",
    "test_label_3 = filter(lambda x: x[1] == 3, zip(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "for ax in axes:\n",
    "    image = next(test_label_2)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image[0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Testing: %i' % image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "for ax in axes:\n",
    "    image = next(test_label_3)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image[0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Testing: %i' % image[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bf0a7eb58a0ecbe06ab574973ab3f2d2fa16eb819a3eb9f056d8b04161afe49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
